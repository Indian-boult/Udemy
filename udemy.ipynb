{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import shadow_useragent\n",
    "import copy\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import threading\n",
    "import random\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from urllib2 import urlopen, Request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.options import DesiredCapabilities\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/Users/thai/anaconda2/lib/python2.7/site-packages/shadow_useragent/getpk.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = shadow_useragent.ShadowUserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY = \"104.156.247.181:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_driver(user_agent):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    PROXY = \"45.32.231.36:31280\"\n",
    "    \n",
    "    options.add_argument(\"--incognito\")\n",
    "#     options.add_argument(\"--headless\")\n",
    "    prefs = {'profile.managed_default_content_settings.images':2, 'disk-cache-size': 4096}\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    options.add_argument('--proxy-server=%s' % PROXY)\n",
    "    options.binary_location = '/Applications/Brave Browser.app/Contents/MacOS/Brave Browser'\n",
    "    driver_path = \"/Users/thai/Desktop/Kris/chromedriver\"\n",
    "    options.add_argument('user-agent='+user_agent)\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find rows contain body\n",
    "def extract_topics(soup):\n",
    "    topics = {}\n",
    "    parentPage = 'https://www.udemy.com'\n",
    "    tables = soup.findAll('div', attrs = {'class':'row'}) \n",
    "    \n",
    "    for row in tables:\n",
    "        columns = row.findAll('div', attrs = {'class':'column-3'})\n",
    "        for col in columns:\n",
    "            uls = col.findAll('ul')\n",
    "            if (len(uls) != 0):\n",
    "                for link in uls:\n",
    "                    for attrib in link.find_all('a', href=True):\n",
    "                        topics[attrib.text] = parentPage + attrib['href']\n",
    "\n",
    "    return topics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_html(url, user_agent):\n",
    "#     ugent = shadow_useragent.ShadowUserAgent()\n",
    "#     user_agent = ugent.percent(0.05)\n",
    "    driver = build_driver(user_agent)\n",
    "    driver.get(url)\n",
    "    element = WebDriverWait(driver,6).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[@class='course-price-text price-text--base-price__discount--1J7vF price-text--black--1qJbH price-text--medium--2clK9 price-text--bold--ldWad']\"))\n",
    "    )\n",
    "    category = WebDriverWait(driver,6).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//a[@class='btn btn-quaternary btn-xs']\"))\n",
    "    )\n",
    "    html = driver.page_source\n",
    "    test_soup = bs.BeautifulSoup(html, 'lxml')\n",
    "    test_search = test_soup.find('div', attrs = {'class': re.compile('curriculum-course-card--container*')})\n",
    "    if test_search is None:\n",
    "        print \"BLOCKED ON \" + url\n",
    "        driver.quit()\n",
    "        ugent = shadow_useragent.ShadowUserAgent()\n",
    "        user_agent = ugent.percent(0.05)\n",
    "        pull_html(url,user_agent)\n",
    "    driver.quit()\n",
    "    return driver, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_page(html):\n",
    "    attribute = bs.BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    ul = attribute.find('ul', attrs = {'class':'pagination pagination-expanded'})\n",
    "    max_page = 1\n",
    "    if ul is not None:\n",
    "        for page in ul.find_all('li'):\n",
    "            if len(page.text) > 0:\n",
    "                next_page = int(page.text)\n",
    "                if max_page < next_page:\n",
    "                    max_page = next_page\n",
    "    return max_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_layer_course_info(topic, html):  \n",
    "    sub_frame = pd.DataFrame(columns=['Course','URL','instructor',\n",
    "                           'Price (full)','Price (discount)','Rank'])\n",
    "    \n",
    "    sub_req = bs.BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    courses = sub_req.find_all('div', attrs = {'class': re.compile('curriculum-course-card--container*')})\n",
    "    category_elem = sub_req.find('div', attrs = {'class': re.compile('browse-container suppress-xl*')})\n",
    "    category = category_elem.find('a', attrs = {'class': re.compile('btn btn-quaternary btn-xs')}, href=True)\n",
    "    for course in courses:\n",
    "        title = course.find('div', attrs = {'class': re.compile('list-view-course-card--title*')})\n",
    "        instructor = course.find('div', attrs = {'class': re.compile('list-view-course-card--instructor*')})\n",
    "        rate_price = course.find('div', attrs = {'class': re.compile('list-view-course-card--price-rating*')})\n",
    "        course_url = course.find('a', href=True)\n",
    "        \n",
    "        if title is None:\n",
    "            continue\n",
    "        \n",
    "        prices = re.compile(\"(\\d+.\\d{2}|Free)\")\n",
    "        ratings = re.compile(\"\\d.\\d\\(.*\\)\")\n",
    "        \n",
    "        string_no_rate = re.sub('\\d.\\d\\(.*\\)', '', rate_price.text)\n",
    "        course_price = prices.findall(string_no_rate)\n",
    "        \n",
    "        o_price = '0'\n",
    "        c_price = '0'\n",
    "        rank = ''\n",
    "\n",
    "        if(len(course_price) == 2):\n",
    "            o_price = course_price[1]\n",
    "            c_price = course_price[0]\n",
    "        elif (len(course_price) == 1):\n",
    "            o_price = '0'\n",
    "            c_price = course_price[0]\n",
    "            \n",
    "        if ratings is not None:\n",
    "            rank = ratings.search(rate_price.text).group()\n",
    "        else:\n",
    "            rank = ''\n",
    "        \n",
    "        data = Orderd{'Course':title.text,\n",
    "                 'URL':'www.udemy.com'+course_url['href'],\n",
    "                 'instructor':instructor.text,\n",
    "                 'Price (full)':o_price,\n",
    "                 'Price (discount)':c_price,\n",
    "                 'Rank':rank,\n",
    "                 'Category 1': category.text,\n",
    "                 'Category 2': '',\n",
    "                 'Category 3': topic}\n",
    "        \n",
    "        sub_frame = sub_frame.append(pd.DataFrame([data],index=[0]), ignore_index=True, sort=False)\n",
    "    return sub_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(topic, url, user_agent):\n",
    "    print \"Starting : \" + topic\n",
    "    df = pd.DataFrame(columns=['Course','URL','instructor',\n",
    "                           'Price (full)','Price (discount)','Rank','Category 1','Category 2','Category 3'])\n",
    "    driver,html = pull_html(url,user_agent)\n",
    "    driver.quit()\n",
    "    page_count = find_max_page(html)\n",
    "    frame = first_layer_course_info(topic, html)\n",
    "    df = df.append(frame, ignore_index=True, sort=False)\n",
    "    for i in range(2, page_count+1):\n",
    "        next_url = url+\"?p=\"+str(i)\n",
    "        print next_url\n",
    "        driver, html = pull_html(next_url, user_agent)\n",
    "        frame = first_layer_course_info(topic, html)\n",
    "        df = df.append(frame, ignore_index=True, sort=False)\n",
    "        \n",
    "    return driver,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = ua.percent(0.05)\n",
    "agent = ua.random\n",
    "headers = {'User-Agent': agent}\n",
    "req_url = 'https://www.udemy.com/sitemap'\n",
    "req = Request(url=req_url, headers=headers) \n",
    "html = urlopen(req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs.BeautifulSoup(html,'html5lib')\n",
    "topics = extract_topics(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(topic, job_list):\n",
    "    ugent = shadow_useragent.ShadowUserAgent()\n",
    "    user_agent = ugent.percent(0.05)\n",
    "    url = topics[topic]\n",
    "    drv,dframe = scrape(topic, url, user_agent)\n",
    "    dframe.to_csv('~/Desktop/Kris/out/'+topic+'.csv', index = None, header=True,encoding = 'utf-8')\n",
    "#     print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = [os.path.split(s)[1].rsplit('.', 1)[0] for s in glob.glob(os.getcwd() + \"/out/*.csv\")]\n",
    "counter = 0\n",
    "for topic in topics:\n",
    "    if topic not in done:\n",
    "        if counter == 10:\n",
    "            break\n",
    "        counter += 1\n",
    "        t1 = threading.Thread(target=task, args=(topic,done, ))\n",
    "        t1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
